{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import openai\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import json\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/screen_eval.json', 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = # key here\n",
    "api_org = # org key here\n",
    "\n",
    "openai.api_key = api_key\n",
    "openai.organization = api_org\n",
    "\n",
    "async def request(prompt, model='gpt-3.5-turbo'):\n",
    "    async with aiohttp.ClientSession() as aiohttp_client_session:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=1,\n",
    "        )\n",
    "        result = response.choices[0].message['content']\n",
    "        print(result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_answer =[]\n",
    "correct_answers=[]\n",
    "clean_time=[]\n",
    "messy_time=[]\n",
    "\n",
    "for idx in tqdm(range(len(data['convo']))):\n",
    "    t0m = time.time()\n",
    "    decrease=0\n",
    "    while True:\n",
    "        t0=time.time()\n",
    "        convo = ' '.join(data['original_convo'][str(idx)].replace('\\n', ' \\n').split(' ')[:2600-decrease])\n",
    "        prompt = f\"\"\"{convo}\n",
    "\n",
    "        Question: does the previous conversation factually imply \"{data['inferred_summary'][str(idx)]}\"? Answer Yes or No.\n",
    "        \"\"\"\n",
    "        response = await request(prompt, model='gpt-3.5-turbo')\n",
    "        sr = response.lower()\n",
    "        binary_answer.append('yes' in sr)\n",
    "        correct_answers.append(data['agg_label'][str(idx)])\n",
    "        t1=time.time()\n",
    "        time.sleep(2)\n",
    "        break\n",
    "\n",
    "    t1m = time.time()\n",
    "    clean_time.append(t1-t0)\n",
    "    messy_time.append(t1m-t0m)\n",
    "\n",
    "with open('chatgpt_eval_results.json', 'w') as file:\n",
    "    json.dump([binary_answer, correct_answers, clean_time, messy_time], file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(correct_answers, binary_answer, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_answer =[]\n",
    "correct_answers=[]\n",
    "clean_time=[]\n",
    "messy_time=[]\n",
    "\n",
    "for idx in tqdm(range(len(data['convo']))):\n",
    "    t0m = time.time()\n",
    "    decrease=0\n",
    "    while True:\n",
    "        t0=time.time()\n",
    "        convo = ' '.join(data['original_convo'][str(idx)].replace('\\n', ' \\n').split(' ')[:2600-decrease])\n",
    "        prompt = f\"\"\"{convo}\n",
    "\n",
    "        Question: does the previous conversation factually imply \"{data['inferred_summary'][str(idx)]}\"? Answer Yes or No.\n",
    "        \"\"\"\n",
    "        response = await request(prompt, model='gpt-4')\n",
    "        sr = response.lower()\n",
    "        binary_answer.append('yes' in sr)\n",
    "        correct_answers.append(data['agg_label'][str(idx)])\n",
    "        t1=time.time()\n",
    "        time.sleep(2)\n",
    "        break\n",
    "\n",
    "    t1m = time.time()\n",
    "    clean_time.append(t1-t0)\n",
    "    messy_time.append(t1m-t0m)\n",
    "\n",
    "with open('gpt_4_eval_results.json', 'w') as file:\n",
    "    json.dump([binary_answer, correct_answers, clean_time, messy_time], file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(correct_answers, binary_answer, average='macro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ss_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
